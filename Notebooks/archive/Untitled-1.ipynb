{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute token counts for both tokenization methods\n",
    "df[\"simple_token_count\"] = df[\"title_tokens_simple\"].apply(len)\n",
    "df[\"hf_token_count\"] = df[\"title_tokens_hf\"].apply(len)\n",
    "\n",
    "# Create a summary table\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Method\": [\"Simple Tokenizer\", \"Hugging Face Tokenizer\"],\n",
    "    \"Average Tokens\": [df[\"simple_token_count\"].mean(), df[\"hf_token_count\"].mean()],\n",
    "    \"Min Tokens\": [df[\"simple_token_count\"].min(), df[\"hf_token_count\"].min()],\n",
    "    \"Max Tokens\": [df[\"simple_token_count\"].max(), df[\"hf_token_count\"].max()]\n",
    "})\n",
    "\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot token count distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df[\"simple_token_count\"], bins=30, alpha=0.6, label=\"Simple Tokenizer\", color=\"blue\")\n",
    "plt.hist(df[\"hf_token_count\"], bins=30, alpha=0.6, label=\"Hugging Face Tokenizer\", color=\"orange\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Token Counts\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random sample of 10 rows\n",
    "sample = df.sample(10, random_state=42)\n",
    "\n",
    "# Plot token counts for the sample\n",
    "x = range(len(sample))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, sample[\"simple_token_count\"], width=width, label=\"Simple Tokenizer\", color=\"blue\", alpha=0.6)\n",
    "plt.bar([i + width for i in x], sample[\"hf_token_count\"], width=width, label=\"Hugging Face Tokenizer\", color=\"orange\", alpha=0.6)\n",
    "plt.xlabel(\"Sample Rows\")\n",
    "plt.ylabel(\"Token Count\")\n",
    "plt.title(\"Token Counts for Sample Rows\")\n",
    "plt.xticks([i + width / 2 for i in x], sample.index, rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute token count differences\n",
    "df[\"token_count_difference\"] = df[\"hf_token_count\"] - df[\"simple_token_count\"]\n",
    "\n",
    "# Plot token count differences\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df[\"token_count_difference\"], bins=30, color=\"purple\", alpha=0.7)\n",
    "plt.axvline(df[\"token_count_difference\"].mean(), color=\"red\", linestyle=\"--\", label=\"Mean Difference\")\n",
    "plt.xlabel(\"Difference in Token Count (HF - Simple)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Difference in Token Counts Between Tokenizers\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten token lists and calculate frequencies\n",
    "simple_token_flat = [token for tokens in df[\"title_tokens_simple\"] for token in tokens]\n",
    "hf_token_flat = [token for tokens in df[\"title_tokens_hf\"] for token in tokens]\n",
    "\n",
    "# Get top 20 tokens by frequency\n",
    "simple_token_freq = Counter(simple_token_flat).most_common(20)\n",
    "hf_token_freq = Counter(hf_token_flat).most_common(20)\n",
    "\n",
    "# Plot token frequency for Simple Tokenizer\n",
    "plt.figure(figsize=(12, 6))\n",
    "simple_tokens, simple_freqs = zip(*simple_token_freq)\n",
    "plt.bar(simple_tokens, simple_freqs, color=\"blue\", alpha=0.7, label=\"Simple Tokenizer\")\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 20 Tokens by Frequency (Simple Tokenizer)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot token frequency for Hugging Face Tokenizer\n",
    "plt.figure(figsize=(12, 6))\n",
    "hf_tokens, hf_freqs = zip(*hf_token_freq)\n",
    "plt.bar(hf_tokens, hf_freqs, color=\"orange\", alpha=0.7, label=\"Hugging Face Tokenizer\")\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 20 Tokens by Frequency (Hugging Face Tokenizer)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Join tokens for TF-IDF analysis\n",
    "df[\"simple_text\"] = df[\"title_tokens_simple\"].apply(lambda tokens: \" \".join(tokens))\n",
    "df[\"hf_text\"] = df[\"title_tokens_hf\"].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "# TF-IDF for Simple Tokenizer\n",
    "tfidf_simple = TfidfVectorizer(max_features=20)\n",
    "simple_tfidf_matrix = tfidf_simple.fit_transform(df[\"simple_text\"])\n",
    "simple_tfidf_df = pd.DataFrame(simple_tfidf_matrix.toarray(), columns=tfidf_simple.get_feature_names_out())\n",
    "\n",
    "# TF-IDF for Hugging Face Tokenizer\n",
    "tfidf_hf = TfidfVectorizer(max_features=20)\n",
    "hf_tfidf_matrix = tfidf_hf.fit_transform(df[\"hf_text\"])\n",
    "hf_tfidf_df = pd.DataFrame(hf_tfidf_matrix.toarray(), columns=tfidf_hf.get_feature_names_out())\n",
    "\n",
    "# TF-IDF for SpaCy fields\n",
    "df[\"spacy_abstract_text\"] = df[\"disease_abstract_spacy\"].apply(lambda entities: \" \".join(entities))\n",
    "df[\"spacy_title_text\"] = df[\"disease_title_spacy\"].apply(lambda entities: \" \".join(entities))\n",
    "\n",
    "tfidf_spacy_abstract = TfidfVectorizer(max_features=20)\n",
    "spacy_abstract_matrix = tfidf_spacy_abstract.fit_transform(df[\"spacy_abstract_text\"])\n",
    "spacy_abstract_tfidf_df = pd.DataFrame(spacy_abstract_matrix.toarray(), columns=tfidf_spacy_abstract.get_feature_names_out())\n",
    "\n",
    "tfidf_spacy_title = TfidfVectorizer(max_features=20)\n",
    "spacy_title_matrix = tfidf_spacy_title.fit_transform(df[\"spacy_title_text\"])\n",
    "spacy_title_tfidf_df = pd.DataFrame(spacy_title_matrix.toarray(), columns=tfidf_spacy_title.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF-IDF Matrix (SpaCy Abstract):\")\n",
    "spacy_abstract_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTF-IDF Matrix (SpaCy Title):\")\n",
    "spacy_title_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Word clouds for tokenized data\n",
    "simple_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(simple_token_flat))\n",
    "hf_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(hf_token_flat))\n",
    "\n",
    "# Word clouds for SpaCy entities\n",
    "spacy_abstract_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"spacy_abstract_text\"]))\n",
    "spacy_title_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"spacy_title_text\"]))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(simple_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud: Simple Tokenizer\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(hf_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud: Hugging Face Tokenizer\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(spacy_abstract_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud: SpaCy Abstract Entities\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(spacy_title_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud: SpaCy Title Entities\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'parsed_date' is datetime\n",
    "df[\"year\"] = df[\"parsed_date\"].dt.year\n",
    "\n",
    "# Flatten and group entities by year\n",
    "abstract_entities_by_year = df.groupby(\"year\")[\"disease_abstract_spacy\"].apply(lambda x: [entity for entities in x for entity in entities])\n",
    "title_entities_by_year = df.groupby(\"year\")[\"disease_title_spacy\"].apply(lambda x: [entity for entities in x for entity in entities])\n",
    "\n",
    "# Count top entities per year\n",
    "abstract_top_entities_by_year = abstract_entities_by_year.apply(lambda entities: Counter(entities).most_common(5))\n",
    "title_top_entities_by_year = title_entities_by_year.apply(lambda entities: Counter(entities).most_common(5))\n",
    "\n",
    "print(\"Top Entities by Year (Abstract):\")\n",
    "print(abstract_top_entities_by_year)\n",
    "\n",
    "print(\"\\nTop Entities by Year (Title):\")\n",
    "print(title_top_entities_by_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overlap ratio\n",
    "df[\"overlap_ratio\"] = df.apply(\n",
    "    lambda row: len(set(row[\"disease_title_spacy\"]) & set(row[\"disease_abstract_spacy\"])) / max(1, len(set(row[\"disease_title_spacy\"]) | set(row[\"disease_abstract_spacy\"]))),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Average overlap by year\n",
    "overlap_by_year = df.groupby(df[\"parsed_date\"].dt.year)[\"overlap_ratio\"].mean()\n",
    "\n",
    "# Plot overlap\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(overlap_by_year.index, overlap_by_year, marker=\"o\", color=\"purple\", label=\"Title-Abstract Overlap\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Overlap Ratio\")\n",
    "plt.title(\"Title-Abstract Entity Overlap Over the Years\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Group by year for abstract entities\n",
    "abstract_entities_by_year = df.groupby(df[\"parsed_date\"].dt.year)[\"disease_abstract_spacy\"].apply(\n",
    "    lambda x: [entity for entities in x for entity in entities]\n",
    ")\n",
    "abstract_counts_by_year = abstract_entities_by_year.apply(lambda entities: Counter(entities))\n",
    "\n",
    "# Define topics of interest\n",
    "topics = [\"tumor\", \"cancer\", \"infection\", \"diabetes\", \"pain\"]\n",
    "\n",
    "# Create a DataFrame for abstract trends\n",
    "abstract_topic_trends = pd.DataFrame({\n",
    "    topic: abstract_counts_by_year.apply(lambda counts: counts.get(topic, 0)) for topic in topics\n",
    "})\n",
    "abstract_topic_trends.index.name = \"Year\"\n",
    "\n",
    "# Plot abstract trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "for topic in topics:\n",
    "    plt.plot(abstract_topic_trends.index, abstract_topic_trends[topic], label=topic)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Abstract Topic Trends Over the Years\")\n",
    "plt.legend(title=\"Topics\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check overlap between title and abstract entities\n",
    "df[\"entity_overlap\"] = df.apply(\n",
    "    lambda row: len(set(row[\"disease_title_spacy\"]) & set(row[\"disease_abstract_spacy\"])),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Value counts for the overlap\n",
    "overlap_counts = df[\"entity_overlap\"].value_counts()\n",
    "print(\"Entity Overlap Between Title and Abstract:\")\n",
    "print(overlap_counts)\n",
    "\n",
    "# Visualize overlap\n",
    "plt.figure(figsize=(10, 6))\n",
    "overlap_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.xlabel(\"Number of Overlapping Entities\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Overlap Between Title and Abstract Entities\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten entities for titles and abstracts\n",
    "title_entity_counts = Counter(\n",
    "    [entity for entities in df[\"disease_title_spacy\"] for entity in entities]\n",
    ")\n",
    "abstract_entity_counts = Counter(\n",
    "    [entity for entities in df[\"disease_abstract_spacy\"] for entity in entities]\n",
    ")\n",
    "\n",
    "# Create DataFrames for better visualization\n",
    "title_counts_df = pd.DataFrame.from_dict(title_entity_counts, orient=\"index\", columns=[\"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "abstract_counts_df = pd.DataFrame.from_dict(abstract_entity_counts, orient=\"index\", columns=[\"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "print(\"Value Counts Table for Title Entities:\")\n",
    "print(title_counts_df.head(100))\n",
    "\n",
    "print(\"\\nValue Counts Table for Abstract Entities:\")\n",
    "print(abstract_counts_df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten entities for titles and abstracts\n",
    "title_entity_counts = Counter([entity for entities in df[\"disease_title_spacy\"] for entity in entities])\n",
    "abstract_entity_counts = Counter([entity for entities in df[\"disease_abstract_spacy\"] for entity in entities])\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "title_counts_df = pd.DataFrame.from_dict(title_entity_counts, orient=\"index\", columns=[\"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "abstract_counts_df = pd.DataFrame.from_dict(abstract_entity_counts, orient=\"index\", columns=[\"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "print(\"Top 10 Title Entities by Count:\")\n",
    "print(title_counts_df.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Abstract Entities by Count:\")\n",
    "print(abstract_counts_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert set to list for indexing\n",
    "top_entities_list = list(top_entities)\n",
    "\n",
    "# Combine counts for the top entities\n",
    "combined_counts = pd.DataFrame({\n",
    "    \"title\": title_counts_df.loc[top_entities_list][\"count\"].fillna(0),\n",
    "    \"abstract\": abstract_counts_df.loc[top_entities_list][\"count\"].fillna(0),\n",
    "}).sort_values(by=[\"title\", \"abstract\"], ascending=False)\n",
    "\n",
    "# Stacked bar chart\n",
    "combined_counts.plot(kind=\"bar\", stacked=True, figsize=(12, 6), color=[\"blue\", \"orange\"])\n",
    "plt.title(\"Entity Frequencies (Titles vs. Abstracts)\")\n",
    "plt.xlabel(\"Entities\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(title=\"Source\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Prepare data for TF-IDF\n",
    "df[\"title_text\"] = df[\"disease_title_spacy\"].apply(lambda x: \" \".join(x))\n",
    "df[\"abstract_text\"] = df[\"disease_abstract_spacy\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# TF-IDF for Titles\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20)\n",
    "tfidf_title_matrix = tfidf_vectorizer.fit_transform(df[\"title_text\"])\n",
    "tfidf_title_df = pd.DataFrame(tfidf_title_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# TF-IDF for Abstracts\n",
    "tfidf_abstract_matrix = tfidf_vectorizer.fit_transform(df[\"abstract_text\"])\n",
    "tfidf_abstract_df = pd.DataFrame(tfidf_abstract_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"TF-IDF (Titles):\")\n",
    "print(tfidf_title_df.head())\n",
    "\n",
    "print(\"\\nTF-IDF (Abstracts):\")\n",
    "print(tfidf_abstract_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year for title entities\n",
    "title_entities_by_year = df.groupby(df[\"parsed_date\"].dt.year)[\"disease_title_spacy\"].apply(\n",
    "    lambda x: [entity for entities in x for entity in entities]\n",
    ")\n",
    "title_counts_by_year = title_entities_by_year.apply(lambda entities: Counter(entities))\n",
    "\n",
    "# Create a DataFrame for title trends\n",
    "title_topic_trends = pd.DataFrame({\n",
    "    topic: title_counts_by_year.apply(lambda counts: counts.get(topic, 0)) for topic in topics\n",
    "})\n",
    "title_topic_trends.index.name = \"Year\"\n",
    "\n",
    "# Plot title trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "for topic in topics:\n",
    "    plt.plot(title_topic_trends.index, title_topic_trends[topic], label=topic)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Title Topic Trends Over the Years\")\n",
    "plt.legend(title=\"Topics\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly trends for top terms\n",
    "df[\"month_year\"] = df[\"parsed_date\"].dt.to_period(\"M\")  # Group by month\n",
    "monthly_entities = df.groupby(\"month_year\")[\"disease_abstract_spacy\"].apply(lambda x: [entity for entities in x for entity in entities])\n",
    "monthly_counts = monthly_entities.apply(lambda entities: Counter(entities))\n",
    "\n",
    "# Extract frequencies for top entities\n",
    "monthly_top_entities = [\"tumor\", \"cancer\", \"infection\", \"pain\"]\n",
    "monthly_trends = pd.DataFrame({\n",
    "    term: monthly_counts.apply(lambda counts: counts.get(term, 0)) for term in monthly_top_entities\n",
    "})\n",
    "\n",
    "# Plot monthly trends\n",
    "monthly_trends.plot(figsize=(12, 6), marker=\"o\")\n",
    "plt.title(\"Monthly Trends for Top Abstract Entities\")\n",
    "plt.xlabel(\"Month-Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(title=\"Entities\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert set to list for indexing\n",
    "top_entities_list = list(top_entities)\n",
    "\n",
    "# Combine counts for the top entities\n",
    "combined_counts = pd.DataFrame({\n",
    "    \"title\": title_counts_df.loc[top_entities_list][\"count\"].fillna(0),\n",
    "    \"abstract\": abstract_counts_df.loc[top_entities_list][\"count\"].fillna(0),\n",
    "})\n",
    "\n",
    "# Normalize to 100% by dividing each value by the row sum\n",
    "combined_counts_normalized = combined_counts.div(combined_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort the normalized counts (optional)\n",
    "combined_counts_normalized = combined_counts_normalized.sort_values(by=[\"title\", \"abstract\"], ascending=False)\n",
    "\n",
    "# Stacked bar chart with 100% scaling\n",
    "combined_counts_normalized.plot(kind=\"bar\", stacked=True, figsize=(12, 6), color=[\"blue\", \"orange\"])\n",
    "plt.title(\"Entity Frequencies (Titles vs. Abstracts) - 100% Stacked\")\n",
    "plt.xlabel(\"Entities\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.legend(title=\"Source\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
